{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced Demo: Finance + News Assistant using OpenAI Tools and Simulated MCP \ud83e\udde0\ud83d\udcc8\ud83d\udcf0\n",
        "\n",
        "This notebook shows a **more complex, realistic use case** of:\n",
        "\n",
        "- **Real OpenAI tool-calling** (`chat.completions.create` with `tools=`), and\n",
        "- **Simulated MCP tools** that wrap:\n",
        "  - Yahoo Finance (via `yfinance`), and\n",
        "  - Tavily Search API (for company/news search).\n",
        "\n",
        "We build a mini **\"Portfolio Risk & News Assistant\"** where the user can ask:\n",
        "\n",
        "> *\"I hold 50% AAPL and 50% MSFT. Give me current prices, 1-day change, 3 key recent news items per stock, and 2 major risks I should watch this quarter.\"*\n",
        "\n",
        "The flow will be:\n",
        "\n",
        "1. Define simulated **MCP tools**: `get_stock_snapshot`, `get_company_news`.\n",
        "2. Convert these tools \u2192 **OpenAI tools schema**.\n",
        "3. Call a **real OpenAI model** with `tools=`.\n",
        "4. Let the model decide which tools to call and with what arguments.\n",
        "5. Execute the tools in Python (simulating an MCP client calling an MCP server).\n",
        "6. Call the model again with tool results to obtain a **final, well-structured answer**.\n",
        "\n",
        "Every code cell is preceded by a detailed explanation so students can understand exactly what is happening.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Setup \u2013 Install Libraries and Configure API Keys\n",
        "\n",
        "You will need:\n",
        "\n",
        "- `OPENAI_API_KEY` \u2013 for OpenAI.\n",
        "- `TAVILY_API_KEY` \u2013 for Tavily Search (https://tavily.com).\n",
        "\n",
        "We also install:\n",
        "\n",
        "- `openai` \u2013 official OpenAI Python client.\n",
        "- `yfinance` \u2013 for Yahoo Finance data.\n",
        "- `tavily-python` \u2013 Tavily client.\n",
        "\n",
        "Run the cell below. In Colab, you may need to uncomment the `pip install` lines.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# If running in Colab or a fresh environment, uncomment these:\n",
        "# !pip install --upgrade openai yfinance tavily-python\n",
        "\n",
        "import os, json, datetime\n",
        "from typing import Callable, List, Dict, Any\n",
        "\n",
        "import yfinance as yf\n",
        "from openai import OpenAI\n",
        "from tavily import TavilyClient\n",
        "\n",
        "# Check environment variables\n",
        "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
        "\nprint(\"OPENAI_API_KEY set:\", bool(openai_key))\n",
        "print(\"TAVILY_API_KEY set:\", bool(tavily_key))\n",
        "\n",
        "if not openai_key:\n",
        "    print(\"\u26a0\ufe0f Please set OPENAI_API_KEY before running tool calls.\")\n",
        "if not tavily_key:\n",
        "    print(\"\u26a0\ufe0f Please set TAVILY_API_KEY before running Tavily search.\")\n",
        "\n",
        "client = OpenAI(api_key=openai_key) if openai_key else None\n",
        "tavily = TavilyClient(api_key=tavily_key) if tavily_key else None\n",
        "\n",
        "# Model that supports tools\n",
        "MODEL = \"gpt-4o-mini\"  # adjust if needed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Simulated MCP Server: Finance + News Tools\n",
        "\n",
        "Imagine an MCP server that exposes these **capabilities**:\n",
        "\n",
        "1. `get_stock_snapshot` \u2013 given a ticker, return:\n",
        "   - current price\n",
        "   - day change in %\n",
        "   - 52-week high/low\n",
        "2. `get_company_news` \u2013 given a ticker and optional time window, return\n",
        "   - a short summary of recent news (via Tavily).\n",
        "\n",
        "We simulate what `list_tools()` would return as `mcp_tools`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "mcp_tools: List[Dict[str, Any]] = [\n",
        "    {\n",
        "        \"name\": \"get_stock_snapshot\",\n",
        "        \"description\": \"Get current price, daily change, and 52-week range for a stock ticker.\",\n",
        "        \"inputSchema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"ticker\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Stock ticker symbol (e.g., AAPL, MSFT).\",\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"ticker\"],\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"get_company_news\",\n",
        "        \"description\": \"Search recent web/news for a company (by ticker) and return key bullets.\",\n",
        "        \"inputSchema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"ticker\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Stock ticker symbol.\",\n",
        "                },\n",
        "                \"days\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"How many recent days of news context to focus on.\",\n",
        "                    \"default\": 7,\n",
        "                },\n",
        "                \"max_results\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"Maximum number of search results to use.\",\n",
        "                    \"default\": 5,\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"ticker\"],\n",
        "        },\n",
        "    },\n",
        "]\n",
        "\n",
        "print(\"Simulated MCP tools (like list_tools() output):\")\n",
        "for t in mcp_tools:\n",
        "    print(f\"- {t['name']}: {t['description']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. MCP Client: Convert Tools \u2192 OpenAI `tools` Schema\n",
        "\n",
        "Next, an MCP client translates these MCP tool descriptions into\n",
        "OpenAI tool definitions that can be passed to the model.\n",
        "\n",
        "The pattern is:\n",
        "\n",
        "```python\n",
        "tools = [\n",
        "  {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "      \"name\": ..., \"description\": ..., \"parameters\": ...\n",
        "    }\n",
        "  },\n",
        "  ...\n",
        "]\n",
        "```\n",
        "\n",
        "We implement a helper to do this conversion.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def mcp_tools_to_openai_tools(mcp_tools: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    openai_tools: List[Dict[str, Any]] = []\n",
        "    for tool in mcp_tools:\n",
        "        openai_tools.append(\n",
        "            {\n",
        "                \"type\": \"function\",\n",
        "                \"function\": {\n",
        "                    \"name\": tool[\"name\"],\n",
        "                    \"description\": tool[\"description\"],\n",
        "                    \"parameters\": tool[\"inputSchema\"],\n",
        "                },\n",
        "            }\n",
        "        )\n",
        "    return openai_tools\n",
        "\n",
        "openai_tools = mcp_tools_to_openai_tools(mcp_tools)\n",
        "\n",
        "print(\"OpenAI tools schema that will be sent to the model:\\n\")\n",
        "print(json.dumps(openai_tools, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Implement Tool Logic (Simulated MCP `call_tool`)\n",
        "\n",
        "Now we define actual Python functions for our tools. In a real MCP server these\n",
        "would be the bodies of `@mcp.tool()` functions.\n",
        "\n",
        "### `get_stock_snapshot(ticker)`\n",
        "\n",
        "Uses **Yahoo Finance** via `yfinance` to fetch:\n",
        "\n",
        "- current price,\n",
        "- day change %, and\n",
        "- 52-week high/low.\n",
        "\n",
        "### `get_company_news(ticker, days, max_results)`\n",
        "\n",
        "Uses **Tavily** to search for recent news about the company.\n",
        "We keep the output compact and structured so the model can reason about it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def tool_get_stock_snapshot(ticker: str) -> str:\n",
        "    \"\"\"Fetch basic stock snapshot using Yahoo Finance (yfinance).\n",
        "\n",
        "    Returns a compact string summary for the LLM.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        t = yf.Ticker(ticker)\n",
        "        info = t.fast_info\n",
        "        current = info.get(\"last_price\") or info.get(\"last_close\")\n",
        "        prev_close = info.get(\"previous_close\") or info.get(\"last_close\")\n",
        "        high_52w = info.get(\"year_high\")\n",
        "        low_52w = info.get(\"year_low\")\n",
        "        currency = info.get(\"currency\", \"USD\")\n",
        "\n",
        "        change_pct = None\n",
        "        if current and prev_close and prev_close != 0:\n",
        "            change_pct = (current - prev_close) / prev_close * 100.0\n",
        "\n",
        "        parts = [f\"Ticker: {ticker}\"]\n",
        "        if current is not None:\n",
        "            parts.append(f\"Current price: {current:.2f} {currency}\")\n",
        "        if change_pct is not None:\n",
        "            parts.append(f\"Day change: {change_pct:+.2f}% vs previous close\")\n",
        "        if low_52w is not None and high_52w is not None:\n",
        "            parts.append(f\"52-week range: {low_52w:.2f}\u2013{high_52w:.2f} {currency}\")\n",
        "\n",
        "        return \" | \".join(parts)\n",
        "    except Exception as e:  # noqa: BLE001\n",
        "        return f\"Error fetching data for {ticker}: {e}\"\n",
        "\n",
        "\n",
        "def tool_get_company_news(ticker: str, days: int = 7, max_results: int = 5) -> str:\n",
        "    \"\"\"Use Tavily to fetch recent news-like context for the company.\n",
        "\n",
        "    Returns a short bullet-style text summary.\n",
        "    \"\"\"\n",
        "    if tavily is None:\n",
        "        return \"Tavily client not configured (no TAVILY_API_KEY).\"\n",
        "\n",
        "    today = datetime.date.today()\n",
        "    start_date = today - datetime.timedelta(days=days)\n",
        "    query = f\"{ticker} stock company news after {start_date.isoformat()}\"\n",
        "\n",
        "    try:\n",
        "        resp = tavily.search(\n",
        "            query=query,\n",
        "            search_depth=\"basic\",\n",
        "            max_results=max_results,\n",
        "        )\n",
        "    except Exception as e:  # noqa: BLE001\n",
        "        return f\"Error querying Tavily for {ticker}: {e}\"\n",
        "\n",
        "    results = resp.get(\"results\", []) if isinstance(resp, dict) else resp\n",
        "    if not results:\n",
        "        return f\"No recent results found for {ticker}.\"\n",
        "\n",
        "    bullets = []\n",
        "    for r in results:\n",
        "        title = r.get(\"title\", \"(no title)\")\n",
        "        snippet = r.get(\"content\", \"\")[:200]\n",
        "        bullets.append(f\"- {title}: {snippet}...\")\n",
        "\n",
        "    return \"\\n\".join(bullets)\n",
        "\n",
        "\n",
        "# Registry mapping tool names \u2192 implementations\n",
        "TOOL_REGISTRY: Dict[str, Callable[..., str]] = {\n",
        "    \"get_stock_snapshot\": tool_get_stock_snapshot,\n",
        "    \"get_company_news\": tool_get_company_news,\n",
        "}\n",
        "\n",
        "print(\"Registered local tool implementations:\")\n",
        "for name in TOOL_REGISTRY:\n",
        "    print(\"-\", name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Helper \u2013 Execute Tool Calls from the Model\n",
        "\n",
        "When the OpenAI model responds with `tool_calls`, we need to:\n",
        "\n",
        "1. Parse the **tool name** and **arguments JSON**.\n",
        "2. Look up the function in `TOOL_REGISTRY`.\n",
        "3. Run it.\n",
        "4. Create a `role=\"tool\"` message with the result, which will be fed back to the model.\n",
        "\n",
        "In a real MCP setup, step 3 would actually call `client_session.call_tool(...)` and talk\n",
        "to a separate MCP server. Here we keep it in-process for clarity.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def execute_tool_call_from_model(tool_call) -> Dict[str, Any]:\n",
        "    \"\"\"Execute one tool_call object from the model and return a tool message.\n",
        "\n",
        "    This simulates what an MCP client would do after reading tool_calls.\n",
        "    \"\"\"\n",
        "    tool_name = tool_call.function.name\n",
        "    args = json.loads(tool_call.function.arguments or \"{}\")\n",
        "    fn = TOOL_REGISTRY.get(tool_name)\n",
        "    if fn is None:\n",
        "        content = f\"Error: unknown tool '{tool_name}'\"\n",
        "    else:\n",
        "        try:\n",
        "            content = fn(**args)\n",
        "        except Exception as e:  # noqa: BLE001\n",
        "            content = f\"Error executing tool {tool_name}: {e}\"\n",
        "\n",
        "    tool_message = {\n",
        "        \"role\": \"tool\",\n",
        "        \"tool_call_id\": tool_call.id,\n",
        "        \"content\": content,\n",
        "    }\n",
        "    return tool_message\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. First OpenAI Call \u2013 Complex Portfolio Query\n",
        "\n",
        "We now send a **richer user query** that involves multiple tickers and higher-level\n",
        "reasoning:\n",
        "\n",
        "> *\"I hold 50% AAPL and 50% MSFT. Give me current prices, 1-day change, 2\u20133 key recent news items per stock, and 2 main risks I should watch this quarter.\"*\n",
        "\n",
        "We include a **system message** gently instructing the model to use tools for\n",
        "live finance/news data whenever possible.\n",
        "\n",
        "The model will:\n",
        "\n",
        "1. Read the tool list (`get_stock_snapshot`, `get_company_news`).\n",
        "2. Decide which ones to call and with what arguments.\n",
        "3. Return `tool_calls` describing those calls.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if client is None:\n",
        "    print(\"\u274c OpenAI client is not configured. Set OPENAI_API_KEY and rerun setup.\")\n",
        "else:\n",
        "    system_prompt = (\n",
        "        \"You are a portfolio risk assistant. \"\n",
        "        \"Use tools for factual finance data and recent news when available. \"\n",
        "        \"Then synthesize risks and insights in clear language.\"\n",
        "    )\n",
        "\n",
        "    user_query = (\n",
        "        \"I hold 50% AAPL and 50% MSFT. \"\n",
        "        \"Give me current prices, 1-day change, 2\u20133 key recent news items per stock, \"\n",
        "        \"and 2 main risks I should watch this quarter.\"\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_query},\n",
        "    ]\n",
        "\n",
        "    print(\"Sending first request to OpenAI with tools...\\n\")\n",
        "    first_response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        tools=openai_tools,\n",
        "    )\n",
        "\n",
        "    first_message = first_response.choices[0].message\n",
        "    print(\"Raw first message from model (repr):\\n\")\n",
        "    print(first_message)\n",
        "\n",
        "    tool_calls = first_message.tool_calls or []\n",
        "    if tool_calls:\n",
        "        print(\"\\n\u2705 Model requested tool calls:\")\n",
        "        for tc in tool_calls:\n",
        "            print(f\"- Tool name: {tc.function.name}\")\n",
        "            print(f\"  Arguments JSON: {tc.function.arguments}\")\n",
        "    else:\n",
        "        print(\"\\n\u2139\ufe0f Model did not request any tool calls.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Execute Tool Calls and Ask for Final Answer\n",
        "\n",
        "Now we:\n",
        "\n",
        "1. Execute each tool call via `execute_tool_call_from_model(...)`.\n",
        "2. Build the **full conversation history**:\n",
        "   - system message,\n",
        "   - user message,\n",
        "   - first assistant message (with tool_calls),\n",
        "   - all `role=\"tool\"` messages with tool outputs.\n",
        "3. Call the model again and let it synthesize a final answer that mixes:\n",
        "   - numbers from Yahoo Finance,\n",
        "   - recent news from Tavily,\n",
        "   - and its own reasoning about portfolio risk.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if client is None:\n",
        "    print(\"\u274c OpenAI client is not configured. Set OPENAI_API_KEY and rerun setup.\")\n",
        "else:\n",
        "    tool_messages: List[Dict[str, Any]] = []\n",
        "    for tc in (tool_calls or []):\n",
        "        tm = execute_tool_call_from_model(tc)\n",
        "        tool_messages.append(tm)\n",
        "\n",
        "    print(\"Tool messages generated after executing tools:\\n\")\n",
        "    print(json.dumps(tool_messages, indent=2))\n",
        "\n",
        "    # Build full conversation history\n",
        "    full_messages: List[Dict[str, Any]] = []\n",
        "    full_messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "    full_messages.append({\"role\": \"user\", \"content\": user_query})\n",
        "\n",
        "    if tool_calls:\n",
        "        full_messages.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": first_message.content or \"\",\n",
        "            \"tool_calls\": [tc.to_dict() for tc in tool_calls],\n",
        "        })\n",
        "        full_messages.extend(tool_messages)\n",
        "    else:\n",
        "        full_messages.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": first_message.content or \"\",\n",
        "        })\n",
        "\n",
        "    print(\"\\nSending second request to OpenAI with tool results...\\n\")\n",
        "    second_response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=full_messages,\n",
        "    )\n",
        "\n",
        "    final_message = second_response.choices[0].message\n",
        "    print(\"Final assistant message (repr):\\n\")\n",
        "    print(final_message)\n",
        "\n",
        "    print(\"\\nAs plain text:\\n\")\n",
        "    print(final_message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Recap: Why This is a \"Complex\" but Clear Use Case\n",
        "\n",
        "You have now seen, end-to-end, how to build a **multi-tool, real-data assistant**:\n",
        "\n",
        "1. **Simulated MCP server** defines high-level tools:\n",
        "   - `get_stock_snapshot` (Yahoo Finance via yfinance),\n",
        "   - `get_company_news` (Tavily search).\n",
        "2. **MCP client** converts those tools into OpenAI `tools` format.\n",
        "3. **First model call**:\n",
        "   - Receives user query + tool list.\n",
        "   - Chooses which tools to call (with arguments) using `tool_calls`.\n",
        "4. **Client executes tools**:\n",
        "   - Calls local functions (simulating MCP `call_tool`).\n",
        "   - Produces `role=\"tool\"` messages with compact summaries.\n",
        "5. **Second model call**:\n",
        "   - Sees tool outputs.\n",
        "   - Synthesizes a final answer that mixes live data, news, and reasoning.\n",
        "\n",
        "This is exactly the pattern you can generalize to:\n",
        "\n",
        "- multiple asset classes,\n",
        "- more tools (e.g., risk calculators, scenario simulators),\n",
        "- or even a full agentic system where the model loops through tool calls.\n",
        "\n",
        "From a **teaching** perspective, this notebook combines:\n",
        "\n",
        "- Real APIs (Yahoo Finance + Tavily),\n",
        "- Real OpenAI tool-calling,\n",
        "- and the conceptual framing of **MCP tools** as capabilities the model can discover and use.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}